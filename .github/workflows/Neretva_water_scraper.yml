name: Daily Scraper

on:
  schedule:
    - cron: "0 11 * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python with pip cache
        uses: actions/setup-python@v5
        with:
          python-version: "3.9"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          sudo add-apt-repository -y ppa:mozillateam/ppa
          sudo apt-get update
          sudo apt-get install -y firefox \
            libgtk-3-0 libdbus-glib-1-2 libx11-xcb1 libxtst6 libxrandr2 \
            libxss1 libnss3 libxcb-shm0 libxcomposite1 libxcursor1 \
            libxdamage1 libxi6 xauth xvfb

      - name: Run scraper and save output
        run: python GH_HRvode_scraper.py > output.txt

      - name: Commit and push results
        run: |
          git config --local user.name "GitHub Action"
          git config --local user.email "action@github.com"
          git add output.txt
          git commit -m "Daily scrape: $(date -u '+%Y-%m-%d')" || echo "Nothing to commit"

      - name: Configure git for push
        run: |
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git

      - name: Push changes
        run: git push
